{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import os, sys\n",
    "import random\n",
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "# options.headless = True\n",
    "options.add_argument(\"window-size=1920x1080\")\n",
    "\n",
    "if getattr(sys, 'frozen', False):\n",
    "    chromedriver_path = os.path.join(sys._MEIPASS, \"chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(chromedriver_path,options=options)\n",
    "else:\n",
    "    driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://shopping.naver.com')\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_category=driver.find_element_by_xpath('//*[@id=\"header\"]/div/div[2]/div/a[3]')\n",
    "all_category.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 패션의류, 패션잡화, 디지털/가전, 가구/인테리어, 스포츠/레저, 생활/건강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_clothes=driver.find_element_by_xpath('//*[@id=\"_fashionCategory1\"]')\n",
    "fashion_etc=driver.find_element_by_xpath('//*[@id=\"header\"]/div/div[2]/div/div[2]/div/ul/li[2]/a')\n",
    "digital = driver.find_element_by_xpath('//*[@id=\"_digitalCategory1\"]')\n",
    "furniture = driver.find_element_by_xpath('//*[@id=\"header\"]/div/div[2]/div/div[2]/div/ul/li[5]/a')\n",
    "sports = driver.find_element_by_xpath('//*[@id=\"header\"]/div/div[2]/div/div[2]/div/ul/li[8]/a')\n",
    "life = driver.find_element_by_xpath('//*[@id=\"header\"]/div/div[2]/div/div[2]/div/ul/li[9]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name_list = ['패션의류', '패션잡화','디지털/가전','가구/인테리어','스포츠/레저','생활/건강']\n",
    "\n",
    "category_url_list = ['https://search.shopping.naver.com/category/category/50000000','https://search.shopping.naver.com/category/category/50000001',\n",
    "                'https://search.shopping.naver.com/category/category/50000003','https://search.shopping.naver.com/category/category/50000004',\n",
    "                'https://search.shopping.naver.com/category/category/50000007','https://search.shopping.naver.com/category/category/50000008']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name=pd.DataFrame(data=category_name_list, columns=['카테고리'])\n",
    "category_url=pd.DataFrame(data=category_url_list, columns=['URL'])\n",
    "\n",
    "category = pd.concat([category_name,category_url], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(category.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_frame = pd.DataFrame()\n",
    "category_frame_all=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    \n",
    "    driver.get(category.iloc[i,1])\n",
    "    \n",
    "    category_under = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[*]/div/ul/li[*]/a')\n",
    "    \n",
    "    category_under_name_all = []\n",
    "    category_under_url_all = []\n",
    "    \n",
    "    for l in category_under:\n",
    "        category_under_name=l.text\n",
    "        category_under_name_all.append(category_under_name)\n",
    "        category_name_frame = pd.DataFrame(data=category_under_name_all,columns=['소카테고리 이름'])\n",
    "        \n",
    "        category_under_url = l.get_attribute('href')\n",
    "        category_under_url_all.append(category_under_url)\n",
    "        category_url_frame = pd.DataFrame(data=category_under_url_all, columns = ['소카테고리 url'])\n",
    "    category_upper_name= pd.DataFrame(data = [category.iloc[i,0]]*len(category_url_frame), columns=['대카테고리 이름'])    \n",
    "    category_frame = pd.concat([category_upper_name, category_name_frame,category_url_frame],axis=1, ignore_index=True)\n",
    "    category_frame_all = pd.concat([category_frame_all,category_frame], axis=0, ignore_index=True)\n",
    "    \n",
    "    time.sleep(2)\n",
    " \n",
    "url_base='&frm=NVSHOVS&origQuery&pagingIndex=1&pagingSize=80&productSet=overseas&query&sort=rel&timestamp=&viewType=list'\n",
    "category_frame_all.iloc[:,2]=category_frame_all.iloc[:,2]+url_base\n",
    "\n",
    "url_total = []\n",
    "for v in category_frame_all.iloc[:,2]:\n",
    "    if v not in url_total:\n",
    "        url_total.append(v)\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "x=1\n",
    "while x<80:\n",
    "    if x % 2 ==1:\n",
    "        a.append(x)\n",
    "    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 경과 없이 화면이 멈춰있을 경우 껏다가 다시 실행\n",
      "1/1197\n",
      "패션의류 여성의류 니트/스웨터\n",
      "패션의류 여성의류 니트/스웨터\n",
      "패션의류 여성의류 니트/스웨터\n",
      "패션의류 여성의류 니트/스웨터\n",
      "패션의류 여성의류 니트/스웨터\n",
      "진행 경과 없이 화면이 멈춰있을 경우 껏다가 다시 실행\n",
      "2/1197\n",
      "패션의류 여성의류 카디건\n",
      "패션의류 여성의류 카디건\n",
      "패션의류 여성의류 카디건\n",
      "패션의류 여성의류 카디건\n",
      "패션의류 여성의류 카디건\n",
      "진행 경과 없이 화면이 멈춰있을 경우 껏다가 다시 실행\n",
      "3/1197\n",
      "패션의류 여성의류 원피스\n",
      "패션의류 여성의류 원피스\n",
      "패션의류 여성의류 원피스\n",
      "패션의류 여성의류 원피스\n",
      "패션의류 여성의류 원피스\n",
      "진행 경과 없이 화면이 멈춰있을 경우 껏다가 다시 실행\n"
     ]
    }
   ],
   "source": [
    "title_frame = pd.DataFrame()\n",
    "product_url_frame = pd.DataFrame()\n",
    "image_frame=pd.DataFrame()\n",
    "date_frame=pd.DataFrame()\n",
    "buy_frame = pd.DataFrame()\n",
    "review_frame = pd.DataFrame()\n",
    "price_frame = pd.DataFrame()\n",
    "delivery_frame = pd.DataFrame()\n",
    "seller_grade_frame = pd.DataFrame()\n",
    "cat1_all_frame= pd.DataFrame()\n",
    "cat2_all_frame= pd.DataFrame()\n",
    "cat3_all_frame= pd.DataFrame()\n",
    "\n",
    "check = 0\n",
    "\n",
    "for i in url_total:\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    if getattr(sys, 'frozen', False):\n",
    "        chromedriver_path = os.path.join(sys._MEIPASS, \"chromedriver.exe\")\n",
    "        driver = webdriver.Chrome(chromedriver_path,options=options)\n",
    "    else:\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    print('진행 경과 없이 화면이 멈춰있을 경우 껏다가 다시 실행')\n",
    "\n",
    "    go_to = i\n",
    "\n",
    "    check=check+1\n",
    "\n",
    "    if check==4:\n",
    "        break\n",
    "    else:\n",
    "        None\n",
    "    \n",
    "    print(str(check)+'/'+str(len(url_total)))\n",
    "    \n",
    "    \n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    foreign_country = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/div[1]/ul/li[6]/a/span')\n",
    "    foreign_country_num = int(foreign_country.text.replace(',',''))\n",
    "    \n",
    "    if  foreign_country_num>320 : \n",
    "        for num in range(0,5):\n",
    "            page_next = 'pagingIndex='+str(num+1)\n",
    "            go_url = go_to.replace('pagingIndex=1', page_next)\n",
    "            \n",
    "            driver.get(go_url)\n",
    "            \n",
    "            time.sleep(1.5)\n",
    "            \n",
    "            while True:\n",
    "\n",
    "                where=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "                z=where[len(where)-5]\n",
    "\n",
    "                actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                actions.perform()\n",
    "\n",
    "                z=where[len(where)-1]\n",
    "\n",
    "                actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                actions.perform()\n",
    "\n",
    "                time.sleep(0.01)\n",
    "\n",
    "                test=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "\n",
    "                if len(where)==len(test):\n",
    "                    actions = webdriver.ActionChains(driver).move_to_element(driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/div[3]/div/span'))\n",
    "                    actions.perform()\n",
    "                    break\n",
    "\n",
    "\n",
    "            title_all=[]\n",
    "            product_url_all=[]\n",
    "            \n",
    "            # 상품명, url\n",
    "            titles = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]/li/div/div[2]/div[1]/a')\n",
    "            for i in titles:\n",
    "                title_all.append(i.text)\n",
    "                product_url_all.append(i.get_attribute('href'))\n",
    "\n",
    "            t=pd.DataFrame(data = title_all, columns=['상품명'])\n",
    "            p=pd.DataFrame(data = product_url_all, columns=['상품 URL'])\n",
    "            title_frame = pd.concat([title_frame,t],axis=0, ignore_index=True)\n",
    "            product_url_frame = pd.concat([product_url_frame,p], axis=0, ignore_index=True)\n",
    "            \n",
    "            images=[]\n",
    "            images_all = []\n",
    "            # 이미지 url\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    images = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[1]/div/a/img' %i)\n",
    "                    images_all.append(images.get_attribute('src'))\n",
    "                except:\n",
    "                    images_all.append('이미지 없음')\n",
    "            \n",
    "            if len(images_all)!=len(titles):\n",
    "                while True:\n",
    "                    driver.quit()\n",
    "                    \n",
    "                    if getattr(sys, 'frozen', False):\n",
    "                        chromedriver_path = os.path.join(sys._MEIPASS, \"chromedriver.exe\")\n",
    "                        driver = webdriver.Chrome(chromedriver_path,options=options)\n",
    "                    else:\n",
    "                        driver = webdriver.Chrome(options=options)\n",
    "                        \n",
    "                    driver.get(go_url)\n",
    "            \n",
    "                    time.sleep(1.5)\n",
    "            \n",
    "                    while True:\n",
    "                    \n",
    "                        driver.maximize_window()\n",
    "\n",
    "                        where=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "                        z=where[len(where)-5]\n",
    "\n",
    "                        actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                        actions.perform()\n",
    "\n",
    "                        z=where[len(where)-1]\n",
    "\n",
    "                        actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                        actions.perform()\n",
    "\n",
    "                        time.sleep(0.01)\n",
    "\n",
    "                        test=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "\n",
    "                        if len(where)==len(test):\n",
    "                            actions = webdriver.ActionChains(driver).move_to_element(driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/div[3]/div/span'))\n",
    "                            actions.perform()\n",
    "                            \n",
    "                            for nu in a:\n",
    "                                actions = webdriver.ActionChains(driver).move_to_element(driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]' %nu))\n",
    "                                actions.perform()\n",
    "                                \n",
    "                            title_all=[]\n",
    "                            product_url_all=[]\n",
    "\n",
    "                            # 상품명, url\n",
    "                            titles = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]/li/div/div[2]/div[1]/a')\n",
    "                            for i in titles:\n",
    "                                title_all.append(i.text)\n",
    "                                product_url_all.append(i.get_attribute('href'))\n",
    "\n",
    "                            t=pd.DataFrame(data = title_all, columns=['상품명'])\n",
    "                            p=pd.DataFrame(data = product_url_all, columns=['상품 URL'])\n",
    "                            title_frame = pd.concat([title_frame,t],axis=0, ignore_index=True)\n",
    "                            product_url_frame = pd.concat([product_url_frame,p], axis=0, ignore_index=True)\n",
    "                            \n",
    "                            images_all=[]\n",
    "                           \n",
    "                            for i in range(1, len(titles)+1):\n",
    "                                try:\n",
    "                                    images = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[1]/div/a/img' %i)\n",
    "                                    images_all.append(images.get_attribute('src'))\n",
    "                                except:\n",
    "                                    images_all.append('이미지 없음')\n",
    "                            print('여기야1')\n",
    "                            \n",
    "                            break\n",
    "                    if len(images_all)==len(titles):\n",
    "                        print('여기야2')\n",
    "                        break\n",
    "                images_all=[]\n",
    "                for i in range(1, len(titles)+1):\n",
    "                    try:\n",
    "                        images = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[1]/div/a/img' %i)\n",
    "                        images_all.append(images.get_attribute('src'))\n",
    "                    except:\n",
    "                        images_all.append('이미지 없음')\n",
    "                print('여기야3')\n",
    "\n",
    "            ima = pd.DataFrame(data = images_all, columns=['이미지URL'])\n",
    "            image_frame=pd.concat([image_frame, ima], axis=0, ignore_index=True)\n",
    "\n",
    "            dates_all=[]\n",
    "            # 등록일 \n",
    "            dates = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]/li/div/div[2]/div[5]/span[1]')\n",
    "            for i in dates:\n",
    "                dates_all.append(i.text.replace('등록일 ',''))\n",
    "            da = pd.DataFrame(data = dates_all, columns = ['등록일'])\n",
    "            date_frame = pd.concat([date_frame,da], axis=0, ignore_index=True)\n",
    "\n",
    "            # 구매건수\n",
    "            all_buy = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    buy = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[2]/div[5]/a[2]/em' %i)\n",
    "                    all_buy.append(buy.text)\n",
    "                except:\n",
    "                    all_buy.append('표기 없음')\n",
    "\n",
    "            b= pd.DataFrame(data = all_buy, columns = ['구매 건수'])\n",
    "            buy_frame = pd.concat([buy_frame, b], axis=0, ignore_index=True)\n",
    "\n",
    "            # 별점\n",
    "            star_review = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    star = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[2]/div[5]/a/span/span' %i)\n",
    "                    star_review.append(star.text.replace('별점 ',''))\n",
    "                except:\n",
    "                    star_review.append('표기 없음')\n",
    "\n",
    "            rev = pd.DataFrame(data = star_review, columns = ['별점'])\n",
    "            review_frame = pd.concat([review_frame, rev], axis=0, ignore_index=True)\n",
    "\n",
    "            # 가격\n",
    "            price= []\n",
    "            price_all=[]\n",
    "            price_al=[]\n",
    "            prices = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]/li/div/div[2]/div[2]/strong/span/span')\n",
    "            for i in prices :\n",
    "                price.append(i.text)\n",
    "            for i in price:\n",
    "                u=re.sub('\\\\(.*','',i)\n",
    "                price_al.append(u)\n",
    "\n",
    "            price=[item for item in price_al if item != '최저']\n",
    "            price=[item for item in price if item != '']\n",
    "            for l in price:\n",
    "                price_per=l.replace('원','')\n",
    "                price_all.append(price_per)\n",
    "\n",
    "            pr = pd.DataFrame(data = price_all, columns=['가격'])\n",
    "            price_frame = pd.concat([price_frame, pr], axis=0, ignore_index=True)\n",
    "\n",
    "            # 배송비\n",
    "            delivery=[]\n",
    "            delivery_all = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    delivery_per = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[3]/ul/li[2]/em' %i)\n",
    "                    delivery.append(delivery_per.text)\n",
    "                except:\n",
    "                    delivery.append('표기 없음')\n",
    "\n",
    "            for l in delivery:\n",
    "                l=l.replace('배송비 ','')\n",
    "                delivery_per = l.replace('원','')\n",
    "                delivery_all.append(delivery_per)\n",
    "\n",
    "            de = pd.DataFrame(data = delivery_all, columns=['배송비'])\n",
    "            delivery_frame = pd.concat([delivery_frame, de], axis=0, ignore_index=True)\n",
    "\n",
    "            # 판매자 등급 \n",
    "            seller_grade = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    seller = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[3]/div[2]/span' %i)\n",
    "                    seller_grade.append(seller.text)\n",
    "                except:\n",
    "                    seller_grade.append('표기 없음')\n",
    "\n",
    "            sel = pd.DataFrame(data = seller_grade, columns = ['판매자 등급'])\n",
    "            seller_grade_frame = pd.concat([seller_grade_frame, sel], axis=0, ignore_index=True)\n",
    "            \n",
    "            # 카테고리\n",
    "\n",
    "            cat1 = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[2]/div/h4/a/span[1]')\n",
    "            cat1_frame=pd.DataFrame(data=[cat1.text]*len(sel), columns= ['대분류'])\n",
    "            cat2 = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[2]/div/h4/a/span[2]')\n",
    "            cat2_frame=pd.DataFrame(data=[cat2.text]*len(sel), columns= ['중분류'])\n",
    "            cat3 = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[2]/div/h4/a/span[3]')\n",
    "            cat3_frame=pd.DataFrame(data=[cat3.text]*len(sel), columns= ['소분류'])\n",
    "            \n",
    "            cat1_all_frame = pd.concat([cat1_all_frame,cat1_frame], axis=0, ignore_index=True)\n",
    "            cat2_all_frame = pd.concat([cat2_all_frame,cat2_frame], axis=0, ignore_index=True)\n",
    "            cat3_all_frame = pd.concat([cat3_all_frame,cat3_frame], axis=0, ignore_index=True)\n",
    "            \n",
    "            print(cat1.text,cat2.text,cat3.text, sep=' ')\n",
    "            \n",
    "        driver.quit()\n",
    "\n",
    "            \n",
    "    else :\n",
    "        num_end = math.ceil(foreign_country_num/80)\n",
    "        for num in range(0,num_end+1):\n",
    "            page_next = 'pagingIndex='+str(num+1)\n",
    "            go_url = go_to.replace('pagingIndex=1', page_next)\n",
    "            \n",
    "            driver.get(go_url)\n",
    "            \n",
    "            time.sleep(0.7)\n",
    "            \n",
    "            while True:\n",
    "\n",
    "                where=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "                z=where[len(where)-5]\n",
    "\n",
    "                actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                actions.perform()\n",
    "\n",
    "                z=where[len(where)-1]\n",
    "\n",
    "                actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                actions.perform()\n",
    "\n",
    "                time.sleep(0.01)\n",
    "\n",
    "                test=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "\n",
    "                if len(where)==len(test):\n",
    "                    actions = webdriver.ActionChains(driver).move_to_element(driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/div[3]/div/span'))\n",
    "                    actions.perform()\n",
    "                    break\n",
    "\n",
    "                \n",
    "            title_all=[]\n",
    "            product_url_all=[]\n",
    "            # 상품명, url\n",
    "            titles = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]/li/div/div[2]/div[1]/a')\n",
    "            for i in titles:\n",
    "                title_all.append(i.text)\n",
    "                product_url_all.append(i.get_attribute('href'))\n",
    "\n",
    "            t=pd.DataFrame(data = title_all, columns=['상품명'])\n",
    "            p=pd.DataFrame(data = product_url_all, columns=['상품 URL'])\n",
    "            title_frame = pd.concat([title_frame,t],axis=0, ignore_index=True)\n",
    "            product_url_frame = pd.concat([product_url_frame,p], axis=0, ignore_index=True)\n",
    "\n",
    "            images_all = []\n",
    "            images=[]\n",
    "            # 이미지 url\n",
    "            \n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    images = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[1]/div/a/img' %i)\n",
    "                    images_all.append(images.get_attribute('src'))\n",
    "                except:\n",
    "                    images_all.append('이미지 없음')\n",
    "            if len(images_all)!=len(titles):\n",
    "                while True:\n",
    "                    driver.quit()\n",
    "                    \n",
    "                    if getattr(sys, 'frozen', False):\n",
    "                        chromedriver_path = os.path.join(sys._MEIPASS, \"chromedriver.exe\")\n",
    "                        driver = webdriver.Chrome(chromedriver_path,options=options)\n",
    "                    else:\n",
    "                        driver = webdriver.Chrome(options=options)\n",
    "                        \n",
    "                    driver.get(go_url)\n",
    "            \n",
    "                    time.sleep(0.7)\n",
    "            \n",
    "                    while True:\n",
    "\n",
    "                        where=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "                        z=where[len(where)-5]\n",
    "\n",
    "                        actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                        actions.perform()\n",
    "\n",
    "                        z=where[len(where)-1]\n",
    "\n",
    "                        actions = webdriver.ActionChains(driver).move_to_element(z)\n",
    "                        actions.perform()\n",
    "\n",
    "                        time.sleep(0.01)\n",
    "\n",
    "                        test=driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]')\n",
    "\n",
    "                        if len(where)==len(test):\n",
    "                            actions = webdriver.ActionChains(driver).move_to_element(driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/div[3]/div/span'))\n",
    "                            actions.perform()\n",
    "                            \n",
    "                            for nu in a:\n",
    "                                actions = webdriver.ActionChains(driver).move_to_element(driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]' %nu))\n",
    "                                actions.perform()\n",
    "                            \n",
    "                            break\n",
    "\n",
    "                    if len(images_all)==len(titles):\n",
    "                        break\n",
    "                images_all=[]\n",
    "                for i in range(1, len(titles)+1):\n",
    "                    try:\n",
    "                        images = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[1]/div/a/img' %i)\n",
    "                        images_all.append(images.get_attribute('src'))\n",
    "                    except:\n",
    "                        images_all.append('이미지 없음')\n",
    "\n",
    "            ima = pd.DataFrame(data = images_all, columns=['이미지URL'])\n",
    "            image_frame=pd.concat([image_frame, ima], axis=0, ignore_index=True)\n",
    "\n",
    "            dates_all=[]\n",
    "            # 등록일 \n",
    "            dates = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]/li/div/div[2]/div[5]/span[1]')\n",
    "            for i in dates:\n",
    "                dates_all.append(i.text.replace('등록일 ',''))\n",
    "            da = pd.DataFrame(data = dates_all, columns = ['등록일'])\n",
    "            date_frame = pd.concat([date_frame,da], axis=0, ignore_index=True)\n",
    "\n",
    "            # 구매건수\n",
    "            all_buy = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    buy = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[2]/div[5]/a[2]/em' %i)\n",
    "                    all_buy.append(buy.text)\n",
    "                except:\n",
    "                    all_buy.append('표기 없음')\n",
    "\n",
    "            b= pd.DataFrame(data = all_buy, columns = ['구매 건수'])\n",
    "            buy_frame = pd.concat([buy_frame, b], axis=0, ignore_index=True)\n",
    "\n",
    "            # 별점\n",
    "            star_review = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    star = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[2]/div[5]/a/span/span' %i)\n",
    "                    star_review.append(star.text.replace('별점 ',''))\n",
    "                except:\n",
    "                    star_review.append('표기 없음')\n",
    "\n",
    "            rev = pd.DataFrame(data = star_review, columns = ['별점'])\n",
    "            review_frame = pd.concat([review_frame, rev], axis=0, ignore_index=True)\n",
    "\n",
    "            # 가격\n",
    "            price= []\n",
    "            price_all=[]\n",
    "            price_al=[]\n",
    "            prices = driver.find_elements_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[*]/li/div/div[2]/div[2]/strong/span/span')\n",
    "            for i in prices :\n",
    "                price.append(i.text)\n",
    "            for i in price:\n",
    "                u=re.sub('\\\\(.*','',i)\n",
    "                price_al.append(u)\n",
    "\n",
    "            price=[item for item in price_al if item != '최저']\n",
    "            price=[item for item in price if item != '']\n",
    "            for l in price:\n",
    "                price_per=l.replace('원','')\n",
    "                price_all.append(price_per)\n",
    "\n",
    "            pr = pd.DataFrame(data = price_all, columns=['가격'])\n",
    "            price_frame = pd.concat([price_frame, pr], axis=0, ignore_index=True)\n",
    "\n",
    "            # 배송비\n",
    "            delivery=[]\n",
    "            delivery_all = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    delivery_per = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[3]/ul/li[2]/em' %i)\n",
    "                    delivery.append(delivery_per.text)\n",
    "                except:\n",
    "                    delivery.append('표기 없음')\n",
    "\n",
    "            for l in delivery:\n",
    "                l=l.replace('배송비 ','')\n",
    "                delivery_per = l.replace('원','')\n",
    "                delivery_all.append(delivery_per)\n",
    "\n",
    "            de = pd.DataFrame(data = delivery_all, columns=['배송비'])\n",
    "            delivery_frame = pd.concat([delivery_frame, de], axis=0, ignore_index=True)\n",
    "\n",
    "            # 판매자 등급 \n",
    "            seller_grade = []\n",
    "            for i in range(1, len(titles)+1):\n",
    "                try:\n",
    "                    seller = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[3]/div[1]/ul/div/div[%d]/li/div/div[3]/div[2]/span' %i)\n",
    "                    seller_grade.append(seller.text)\n",
    "                except:\n",
    "                    seller_grade.append('표기 없음')\n",
    "\n",
    "            sel = pd.DataFrame(data = seller_grade, columns = ['판매자 등급'])\n",
    "            seller_grade_frame = pd.concat([seller_grade_frame, sel], axis=0, ignore_index=True)\n",
    "            \n",
    "            # 카테고리\n",
    "\n",
    "            cat1 = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[2]/div/h4/a/span[1]')\n",
    "            cat1_frame=pd.DataFrame(data=[cat1.text]*len(sel), columns= ['대분류'])\n",
    "            cat2 = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[2]/div/h4/a/span[2]')\n",
    "            cat2_frame=pd.DataFrame(data=[cat2.text]*(sel), columns= ['중분류'])\n",
    "            cat3 = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[2]/div/h4/a/span[3]')\n",
    "            cat3_frame=pd.DataFrame(data=[cat3.text]*(sel), columns= ['소분류'])\n",
    "            \n",
    "            cat1_all_frame = pd.concat([cat1_all_frame,cat1_frame], axis=0, ignore_index=True)\n",
    "            cat2_all_frame = pd.concat([cat2_all_frame,cat2_frame], axis=0, ignore_index=True)\n",
    "            cat3_all_frame = pd.concat([cat3_all_frame,cat3_frame], axis=0, ignore_index=True)\n",
    "            \n",
    "            print(cat1.text,cat2.text,cat3.text, sep=' ')\n",
    "        driver.quit()\n",
    "\n",
    "all_frame = pd.concat(\n",
    "    [title_frame, cat1_all_frame, cat2_all_frame, cat3_all_frame, product_url_frame, image_frame, date_frame, buy_frame,\n",
    "     price_frame, delivery_frame, review_frame, seller_grade_frame], axis=1, ignore_index=True)\n",
    "\n",
    "all_frame = all_frame.loc[-(all_frame.iloc[:, 7] == '표기 없음'), :].reset_index().drop(['index'], axis=1)\n",
    "all_frame.columns = ['상품명', '대 카테고리', '중 카테고리', '소 카테고리', '상품URL', '이미지URL', '등록일', '구매건수', '가격', '배송비', '별점(리뷰 평점)',\n",
    "                     '판매자등급']\n",
    "nows = time.localtime()\n",
    "time=str(nows.tm_year)+'-'+str(nows.tm_mon)+'-'+str(nows.tm_mday)\n",
    "name=time+'naver_shop.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(name, engine='xlsxwriter', options={'strings_to_urls': True})\n",
    "all_frame.to_excel(writer)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>상품명</th>\n",
       "      <th>대 카테고리</th>\n",
       "      <th>중 카테고리</th>\n",
       "      <th>소 카테고리</th>\n",
       "      <th>상품URL</th>\n",
       "      <th>이미지URL</th>\n",
       "      <th>등록일</th>\n",
       "      <th>구매건수</th>\n",
       "      <th>가격</th>\n",
       "      <th>배송비</th>\n",
       "      <th>별점(리뷰 평점)</th>\n",
       "      <th>판매자등급</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [상품명, 대 카테고리, 중 카테고리, 소 카테고리, 상품URL, 이미지URL, 등록일, 구매건수, 가격, 배송비, 별점(리뷰 평점), 판매자등급]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
