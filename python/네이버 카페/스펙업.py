from selenium import webdriver
import pandas as pd
import re
import time
import os, sys

options = webdriver.ChromeOptions()
options.headless = True
options.add_argument("window-size=1920x1080")

if getattr(sys, 'frozen', False):
    chromedriver_path = os.path.join(sys._MEIPASS, "chromedriver.exe")
    driver = webdriver.Chrome(chromedriver_path, options=options)
else:
    driver = webdriver.Chrome(options=options)

keyword = ['ëŒ€ë©´', 'ë¹„ëŒ€ë©´', 'ê°•ì˜', 'ìˆ˜ì—…', 'ì½”ë¡œë‚˜', 'ì‹¸ê°•', 'ì˜¨ë¼ì¸', 'ì˜¤í”„ë¼ì¸']

### í˜ì´ì§€ ì´ë™ (ìŠ¤í™ì—…)

driver.get('https://cafe.naver.com/specup')

### ë¡œê·¸ì¸ í˜ì´ì§€ ì´ë™

log_in = driver.find_element_by_xpath('//*[@id="gnb_login_button"]/span[3]')
log_in.click()

### ì•„ì´ë””, ë¹„ë°€ë²ˆí˜¸ ì…ë ¥

id = driver.find_element_by_xpath('//*[@id="id"]')
pw = driver.find_element_by_xpath('//*[@id="pw"]')

id_value = input('ì•„ì´ë””ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”')
pw_value = input('ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”')

driver.execute_script("arguments[0].setAttribute('value', arguments[1])", id, id_value)

time.sleep(0.5)

driver.execute_script("arguments[0].setAttribute('value', arguments[1])", pw, pw_value)

time.sleep(0.5)
### ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­

login = driver.find_element_by_xpath('//*[@id="log.login"]')
login.click()

time.sleep(1)

if (driver.current_url) == 'https://nid.naver.com/nidlogin.login':
    driver.quit()
    raise Exception('ë¡œê·¸ì¸ ì‹¤íŒ¨ ì˜¤ë¥˜')

title_all = []
url_all = []
word_all = []

for word in keyword:

    ### í˜ì´ì§€ ì´ë™ (ìŠ¤í™ì—…)

    driver.get('https://cafe.naver.com/specup')

    #### ëŒ€í•™ìƒ | ì´ì•¼ê¸°ë°© ì¹´í…Œê³ ë¦¬ ì´ë™

    driver.find_element_by_xpath('//*[@id="menuLink1211"]').click()

    ### ê²Œì‹œê¸€ì´ ìˆëŠ” iframeìœ¼ë¡œ ì „í™˜

    iframe = driver.find_element_by_xpath('//*[@id="cafe_main"]')
    driver.switch_to.frame(iframe)

    ### ê¸°ê°„ ì„¤ì •
    driver.find_element_by_xpath('//*[@id="currentSearchDate"]').click()

    time.sleep(0.5)

    try:
        start = driver.find_element_by_xpath('//*[@id="input_1"]')

        start.clear()

        start.send_keys('2019-11-01')

        time.sleep(1)

        driver.find_element_by_xpath('//*[@id="btn_set"]').click()
    except:
        driver.find_element_by_xpath('//*[@id="MessageBoxLayer"]/div/div/div/div/div/div/div[2]/a[2]/img').click()

        start = driver.find_element_by_xpath('//*[@id="input_1"]')
        start.clear()
        start.send_keys('2019-11-01')

        time.sleep(1)

        driver.find_element_by_xpath('//*[@id="btn_set"]').click()

    ### í‚¤ì›Œë“œ ê²€ìƒ‰

    search_space = driver.find_element_by_xpath('//*[@id="query"]')
    search_space.clear()
    search_space.send_keys(word)

    driver.find_element_by_xpath('//*[@id="main-area"]/div[7]/form/div[3]/button').click()

    ### 60ê°œì”© ë³´ê¸°
    driver.find_element_by_xpath('//*[@id="listSizeSelectDiv"]').click()

    time.sleep(0.1)

    driver.find_element_by_xpath('//*[@id="listSizeSelectDiv"]/ul/li[7]/a').click()

    time.sleep(0.1)

    ### í˜ì´ì§€ url ê°€ì ¸ì˜¤ê¸°

    page = driver.find_element_by_xpath('//*[@id="main-area"]/div[7]/a[1]')
    page_base = page.get_attribute('href')

    num = 0
    while True:
        print(word)
        num = num + 1
        page_num = 'page=%d' % num
        url = re.sub('page=1', page_num, page_base)

        driver.get(url)

        ### ê²Œì‹œê¸€ì´ ìˆëŠ” iframeìœ¼ë¡œ ì „í™˜

        iframe = driver.find_element_by_xpath('//*[@id="cafe_main"]')
        driver.switch_to.frame(iframe)

        ### ê²Œì‹œê¸€ì˜ ì œëª©, url ê°€ì ¸ì˜¤ê¸°

        title = driver.find_elements_by_xpath('//*[@id="main-area"]/div[5]/table/tbody/tr[*]/td[1]/div[2]/div/a[1]')

        for i in title:
            title_all.append(i.text)
            url_all.append(i.get_attribute('href'))

            word_all.append(word)

        if (len(title) == 0):
            break

url

### ê²Œì‹œê¸€ ê°€ì ¸ì˜¤ê¸°
content_all = []
review_all = []
date_all = []

page = 0
for i in url_all:

    page = page + 1

    print(page, '/', len(url_all))

    driver.get(i)
    time.sleep(1)
    try:
        result = driver.switch_to.alert
        result.accept()

        content = ' ì‚­ì œëœ ê²Œì‹œê¸€'
        content_all.append(content)
        date = None
        date_all.append(date)
        review = None
        review_all.append(review)

        continue
    except:
        None
    time.sleep(1.2)

    ### ê²Œì‹œê¸€ì˜ ë°ì´í„°ê°€ ìˆëŠ” iframeìœ¼ë¡œ ì „í™˜
    try:
        iframe = driver.find_element_by_xpath('//*[@id="cafe_main"]')
        driver.switch_to.frame(iframe)
    except:
        if len(driver.switch_to.alert) != 0:
            result = driver.switch_to.alert
            result.accept()
            content = ' ì‚­ì œëœ ê²Œì‹œê¸€'
            content_all.append(content)
            date = None
            date_all.append(date)
            review = None
            review_all.append(review)
            continue
        else:
            driver.get(i)

            time.sleep(3)

            iframe = driver.find_element_by_xpath('//*[@id="cafe_main"]')
            driver.switch_to.frame(iframe)

    ### ê²Œì‹œê¸€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°

    try:
        content = driver.find_element_by_class_name('article_viewer')
        content_all.append(content.text)
    except:
        time.sleep(2)

        content = driver.find_element_by_class_name('article_viewer')
        content_all.append(content.text)

    ### ëŒ“ê¸€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°

    review_base = []

    review = driver.find_elements_by_class_name('text_comment')

    if len(review) == 0:
        review = None
        review_base.append(review)
        review_all.append(review_base)

    elif len(review) == 1:
        review_base.append(driver.find_element_by_class_name('text_comment').text)
        review_all.append(review_base)
    else:
        for i in review:
            review_base.append(i.text)
        review_all.append("/".join(review_base))

    ### ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
    try:
        date = driver.find_elements_by_class_name('date')
        for d in date:
            date_all.append("".join(d.text.split('.')[0:3]))
    except:
        time.sleep(2)
        date = driver.find_elements_by_class_name('date')
        for d in date:
            date_all.append("".join(d.text.split('.')[0:3]))

df_original = {'Keyword': word_all, 'Title': title_all, 'Date': date_all, 'Content': content_all, 'Review': review_all,
               'URL': url_all}
df_original = pd.DataFrame(df_original)

#### ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì‚­ì œ
rt = re.compile('https://vo.la/VJbP7\n')
content_all_2 = []
content_all_3 = []
content_all_4 = []

for i in df_original['Content']:
    try:
        if len(rt.findall(i)) == 0:
            content = i
            content_all_2.append(content)
        else:
            content = re.split('https://vo.la/VJbP7\n', i)[0]
            content_all_2.append(content)
    except:
        content = i
        content_all_2.append(content)

rt = re.compile('ğŸ€ìŠ¤í™ì—…ì´ 5ë§Œì›ì„ ì•„ë‚Œì—†ì´ ë“œë¦½ë‹ˆë‹¤')

for i in content_all_2:
    try:
        if len(rt.findall(i)) == 0:
            content = i
            content_all_3.append(content)
        else:
            content = re.split('ğŸ€ìŠ¤í™ì—…ì´ 5ë§Œì›ì„ ì•„ë‚Œì—†ì´ ë“œë¦½ë‹ˆë‹¤', i)[0]
            content_all_3.append(content)
    except:
        content = i
        content_all_3.append(content)

rt = re.compile('ğŸš¨ëŒ€í•™ìƒ ë² ìŠ¤íŠ¸ ì¸ê¸°ê¸€ğŸš¨')

for i in content_all_3:
    try:
        if len(rt.findall(i)) == 0:
            content = i
            content_all_4.append(content)
        else:
            content = re.split('ğŸš¨ëŒ€í•™ìƒ ë² ìŠ¤íŠ¸ ì¸ê¸°ê¸€ğŸš¨', i)[0]
            content_all_4.append(content)
    except:
        content = i
        content_all_4.append(content)

df_original['Content'] = content_all_4

df_original.to_excel('ìŠ¤í™ì—… ì›ë³¸_ì—‘ì…€.xlsx')

df_preprocessed = df_original.drop_duplicates(['Title', 'Date', 'Content', ]).reset_index().drop(['index'], axis=1)
df_preprocessed.to_excel('ìŠ¤í™ì—… ì¤‘ë³µ ì œê±°_ì—‘ì…€.xlsx')

